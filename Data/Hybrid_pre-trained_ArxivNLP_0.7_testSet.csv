text,#label
"Models of human motion commonly focus either on tra- jectory prediction or action classification but rarely both. The marked heterogeneity and intricate compositionality of human motion render each task vulnerable to the data degradation and distributional shift common to real-world scenarios. A sufficiently expressive generative model of ac- tion could in theory enable data conditioning and distribu- tional resilience within a unified framework applicable to both tasks. Here we propose a novel architecture based on hierarchical variational autoencoders and deep graph con- volutional neural networks for generating a holistic model of action over multiple time-scales. We show this Hierar- chical Graph-convolutional Variational Autoencoder (HG- VAE) to be capable of generating coherent actions, detect- ing out-of-distribution data, and imputing missing data by gradient ascent on the model’s posterior. Trained and eval- uated on H3.6M and the largest collection of open source human motion data, AMASS, we show HG-VAE can facil- itate downstream discriminative learning better than base- line models.",1
"Models of human motion commonly focus either on tra- jectory prediction or action classification but rarely both. The marked heterogeneity and intricate compositionality of human motion render each task vulnerable to the data degradation and distributional shift common to real-world scenarios. A sufficiently expressive generative model of ac- tion could in theory enable data conditioning and distribu- tional resilience within a unified framework applicable to both tasks. Here we propose an approach that incorporates a high level of generative model fusion as well as an additional layer of data-driven generative models. Our approach also incorporates a novel and useful component for classification, which is the extraction of sentence sequences using machine translation ( MMT). In this work, we integrate these approaches and an iterative approach that achieves performance comparable to the previous models. Trained and eval- uated on H3.6M and the largest collection of open source human motion data, AMASS, we show HG-VAE can facil- itate downstream discriminative learning better than base- line models.",0
"Genome engineering is undergoing unprecedented development and is now becoming widely available. To ensure responsible biotechnology innovation and to reduce misuse of engineered DNA sequences, it is vital to develop tools to identify the lab-of- origin of engineered plasmids. Genetic engineering attribution (GEA), the ability to make sequence-lab associations, would support forensic experts in this process. Here, we propose a method, based on metric learning, that ranks the most likely labs-of-origin whilst simultaneously generating embeddings for plasmid sequences and labs. These embeddings can be used to perform various downstream tasks, such as clustering DNA sequences and labs, as well as using them as features in machine learning models. Our approach employs a circular shift augmentation approach and is able to correctly rank the lab-of-origin 90% of the time within its top 10 predictions - outperforming all current state-of-the-art approaches. We also demonstrate that we can perform few-shot-learning and obtain 76% top-10 accuracy using only 10% of the sequences. This means, we outperform the previous CNN approach using only one-tenth of the data. We also demonstrate that we are able to extract key signatures in plasmid sequences for particular labs, allowing for an interpretable examination of the model’s outputs.",1
"Genome engineering is undergoing unprecedented development and is now becoming widely available. To ensure responsible biotechnology innovation and to reduce misuse of engineered DNA sequences, it is vital to develop tools to identify the lab-of- origin of engineered plasmids. Genetic engineering attribution (GEA), the ability to make sequence-lab associations, would support forensic experts in this process. Here, we propose a method, called hybrid genetic engineering, in which hybrid genetic engineering of sequence- labeling elements to generate a hybrid sequence of a gene product from a human sequence and use it to create new sequences. These embeddings can be used to perform various downstream tasks, such as clustering DNA sequences and labs, as well as using them as features in machine learning models. Our approach employs a circular shift augmentation approach and is able to correctly rank the lab-of-origin 90% of the time within its top 10 predictions - outperforming all current state-of-the-art approaches. We also demonstrate that we can perform few-shot-learning and obtain 76% top-10 accuracy using only 10% of the sequences. This means, we outperform the previous CNN approach using only one-tenth of the data. We also demonstrate that we are able to extract key signatures in plasmid sequences for particular labs, allowing for an interpretable examination of the model’s outputs.",0
"In recent years, researchers have made significant progress in devising reinforcement-learning algorithms for optimizing linear temporal logic (LTL) objectives and LTL-like objec- tives. Despite these advancements, there are fundamental lim- itations to how well this problem can be solved that previous studies have alluded to but, to our knowledge, have not ex- amined in depth. In this paper, we address theoretically the hardness of learning with general LTL objectives. We for- malize the problem under the probably approximately correct learning in Markov decision processes (PAC-MDP) frame- work, a standard framework for measuring sample complex- ity in reinforcement learning. In this formalization, we prove that the optimal policy for any LTL formula is PAC-MDP- learnable only if the formula is in the most limited class in the LTL hierarchy, consisting of only finite-horizon-decidable properties. Practically, our result implies that it is impossi- ble for a reinforcement-learning algorithm to obtain a PAC- MDP guarantee on the performance of its learned policy after finitely many interactions with an unconstrained environment for non-finite-horizon-decidable LTL objectives.",1
"In recent years, researchers have made significant progress in devising reinforcement-learning algorithms for optimizing linear temporal logic (LTL) objectives and LTL-like objec- tives. Despite these advancements, there are fundamental lim- itations to how well this problem can be solved that previous studies have alluded to but, to our knowledge, have not ex- amined in depth. In this paper, we propose a framework for building an optimal LTL objective and a method to automatically detect and identify unlabeled words using unigram based approaches. We for- malize the problem under the probably approximately correct learning in Markov decision processes (PAC-MDP) frame- work, a standard framework for measuring sample complex- ity in reinforcement learning. In this formalization, we prove that the optimal policy for any LTL formula is PAC-MDP- learnable only if the formula is in the most limited class in the LTL hierarchy, consisting of only finite-horizon-decidable properties. Practically, our result implies that it is impossi- ble for a reinforcement-learning algorithm to obtain a PAC- MDP guarantee on the performance of its learned policy after finitely many interactions with an unconstrained environment for non-finite-horizon-decidable LTL objectives.",0
"Adversarial examples can easily degrade the clas- sification performance in neural networks. Empirical methods for promoting robustness to such examples have been proposed, but often lack both analytical insights and formal guarantees. Recently, some robustness certificates have appeared in the literature based on system theoretic notions. This work pro- poses an incremental dissipativity-based robustness certificate for neural networks in the form of a linear matrix inequality for each layer. We also propose an equivalent spectral norm bound for this certificate which is scalable to neural networks with multiple layers. We demonstrate the improved performance against adversarial attacks on a feed-forward neural network trained on MNIST and an Alexnet trained using CIFAR-10.",1
"Adversarial examples can easily degrade the clas- sification performance in neural networks. Empirical methods for promoting robustness to such examples have been proposed, but often lack both analytical insights and formal guarantees. Recently, some robustness certificates have appeared in the literature based on system theoretic notions. This work pro- poses a possible solution: if we can produce such a certificate that has robustness and confidence annotations, then we can extract comparable CLAS-style information without relying on the CLAS annotations. We also propose an equivalent spectral norm bound for this certificate which is scalable to neural networks with multiple layers. We demonstrate the improved performance against adversarial attacks on a feed-forward neural network trained on MNIST and an Alexnet trained using CIFAR-10.",0
"This paper makes a first step towards a logic of learning from ex- periments. For this, we investigate formal frameworks for modeling the interaction of causal and (qualitative) epistemic reasoning. Crucial for our approach is the idea that the notion of an intervention can be used as a formal expression of a (real or hypothetical) experiment (Pearl 2009; Woodward 2003). In a first step we extend a causal model (Galles and Pearl 1998; Halpern 2000; Pearl 2009; Briggs 2012) with a simple Hintikka-style representation of the epistemic state of an agent. In the resulting setting, one can talk about the knowledge of an agent and information update. The resulting logic can model reasoning about thought experiments. How- ever, it is unable to account for learning from experiments, which is clearly brought out by the fact that it validates the principle of no learning for interventions. Therefore, in a second step we implement a more complex notion of knowledge (Nozick 1981) that allows an agent to observe (meas- ure) certain variables when an experiment is carried out. This extended system does allow for learning from experiments. For all the proposed logics, we provide a sound and complete axiomatization.",1
"This paper makes a first step towards a logic of learning from ex- periments. For this, we investigate formal frameworks for modeling the interaction of causal and (qualitative) epistemic reasoning. Crucial for our approach is the idea that the notion of an intervention can be used as a formal expression of a (real or hypothetical) experiment (Pearl 2009; Woodward 2003). In a first step we extend a causal model (Galles and Pearl 1998; Halpern 2000; Pearl 2009; Briggs 2012) with a simple Hintikka-style representation of the epistemic state of an agent. In the resulting setting, one can talk about the knowledge of an agent and information update. The resulting logic can model reasoning about thought experiments. How- ever, it is unable to account for learning from experiments, which is clearly brought out by the fact that it validates the principle of no learning for interventions. Therefore, in a second step we implement a more complex notion of knowledge (Nozick 1981) that allows an agent to observe (meas- ure) certain variables when an experiment is carried out. This extended system allows the agent to see certain properties of the experimental conditions and then act accordingly. By modeling the interaction of the relevant variables with the  knowledge of the experimental conditions, the agent can then be able to use knowledge that it has acquired prior to the experiment to perform the experiment.",0
"We present a method for the generation of Midi files of piano music. The method models the right and left hands using two networks, where the left hand is conditioned on the right hand. This way, the melody is generated before the harmony. The Midi is represented in a way that is invariant to the musical scale, and the melody is represented, for the purpose of conditioning the harmony, by the content of each bar, viewed as a chord. Finally, notes are added randomly, based on this chord representation, in order to enrich the generated audio. Our experiments show a significant improvement over the state of the art for training on such datasets, and demonstrate the contribution of each of the novel components.",1
"We present a method for the generation of Midi files of piano music. The method models the right and left hands using two networks, where the left hand is conditioned on the right hand. This way, the melody is generated before the harmony. The Midi is represented in a way that is invariant to the musical scale, and the melody is represented, for the purpose of conditioning the harmony, by the content of each bar, viewed as a chord. Finally, notes are added randomly, based on this chord representation, in order to enrich the generated audio. Our experiments show a remarkable improvement in performance of our method. We also show that we could improve the quality of the generated data by using less expensive techniques such as machine learning.",0
"Inspired by the ”Cognitive Hour-glass” model presented in [1], we propose a new framework for developing cognitive architectures aimed at cognitive robotics. The purpose of the proposed framework is foremost to ease the develop- ment of cognitive architectures by encouraging and mitigating cooperation and re-use of existing results. This is done by proposing a framework dividing the development of cognitive architectures into a series of layers that can be considered partly in isolation, and some of which directly relate to other research fields. Finally, we give introductions to and review some topics essential to the proposed framework.",1
"Inspired by the ”Cognitive Hour-glass” model presented in [1], we propose a new framework for developing cognitive architectures aimed at cognitive robotics. The purpose of the proposed framework is foremost to ease the develop- ment of cognitive architectures by encouraging and mitigating cooperation and re-use of existing results. This is done by introducing a new set of neural network architectures to the framework and applying them to the context of task development. Finally, we give introductions to and review some topics essential to the proposed framework.",0
"Machine learning in medical imaging during clinical routine is impaired by changes in scan- ner protocols, hardware, or policies resulting in a heterogeneous set of acquisition settings. When training a deep learning model on an initial static training set, model performance and reliability suffer from changes of acquisition characteristics as data and targets may become inconsistent. Continual learning can help to adapt models to the changing environ- ment by training on a continuous data stream. However, continual manual expert labelling of medical imaging requires substantial effort. Thus, ways to use labelling resources ef- ficiently on a well chosen sub-set of new examples is necessary to render this strategy feasible. Here, we propose a method for continual active learning operating on a stream of medical images in a multi-scanner setting. The approach automatically recognizes shifts in image acquisition characteristics - new domains -, selects optimal examples for labelling and adapts training accordingly. Labelling is subject to a limited budget, resembling typ- ical real world scenarios. To demonstrate generalizability, we evaluate the effectiveness of our method on three tasks: cardiac segmentation, lung nodule detection and brain age estimation. Results show that the proposed approach outperforms other active learning methods, while effectively counteracting catastrophic forgetting.",1
"Machine learning in medical imaging during clinical routine is impaired by changes in scan- ner protocols, hardware, or policies resulting in a heterogeneous set of acquisition settings. When training a deep learning model on an initial static training set, model performance and reliability suffer from changes of acquisition characteristics as data and targets may become inconsistent. Continual learning can help to adapt models to the changing environ- ment by training on a continuous data stream. However, continual manual expert labelling of medical imaging requires substantial effort. Thus, ways to use labelling resources ef- ficiently on a well chosen sub-set of new examples is necessary to render this strategy feasible. Here, we propose an integrated toolkit for automatic annotation of medical imaging , based on a deep embeddings framework for biomedical data, and present a method to automatically infer such annotation results using the full medical image corpus. The approach automatically recognizes shifts in image acquisition characteristics - new domains -, selects optimal examples for labelling and adapts training accordingly. Labelling is subject to a limited budget, resembling typ- ical real world scenarios. To demonstrate generalizability, we evaluate the effectiveness of our method on three tasks: cardiac segmentation, lung nodule detection and brain age estimation. Results show that the proposed approach outperforms other active learning methods, while effectively counteracting catastrophic forgetting.",0
"Even though it has extensively been shown that retrieval specific training of deep neural networks is beneficial for nearest neighbor image search quality, most of these models are trained and tested in the domain of landmarks images. However, some applications use images from various other domains and therefore need a network with good generalization properties - a general-purpose CBIR model. To the best of our knowledge, no testing protocol has so far been introduced to benchmark models with respect to general image retrieval quality. After analyzing popular image retrieval test sets we decided to manually curate GPR1200, an easy to use and accessible but challenging benchmark dataset with a broad range of image categories. This benchmark is subsequently used to evaluate various pretrained models of different architectures on their generalization qualities. We show that large-scale pretraining significantly improves retrieval performance and present experiments on how to further increase these properties by appropriate fine-tuning. With these promising results, we hope to increase interest in the research topic of general-purpose CBIR.",1
"Even though it has extensively been shown that retrieval specific training of deep neural networks is beneficial for nearest neighbor image search quality, most of these models are trained and tested in the domain of landmarks images. However, some applications use images from various other domains and therefore need a network with good generalization properties - a general-purpose CBIR model. To the best of our knowledge, no testing protocol has so far been introduced to benchmark models with respect to general image retrieval quality. After analyzing popular image retrieval test sets we decided to manually curate GPR1200, an easy to use and accessible but challenging benchmark dataset with a broad range of image categories. This benchmark is subsequently used to evaluate various pretrained models of different architectures on their generalization qualities. We show that our model of embedding images with non- native features produces better results on the standard GPR dataset, while at the cost of losing more resources for further evaluation. With these promising results, we hope to increase interest in the research topic of general-purpose CBIR.",0
"The increasing importance of resource-efficient pro- duction entails that manufacturing companies have to create a more dynamic production environment, with flexible manufac- turing machines and processes. To fully utilize this potential of dynamic manufacturing through automatic production planning, formal skill descriptions of the machines are essential. How- ever, generating those skill descriptions in a manual fashion is labor-intensive and requires extensive domain-knowledge. In this contribution an ontology-based semi-automatic skill description system that utilizes production logs and industrial ontologies through inductive logic programming is introduced and benefits and drawbacks of the proposed solution are evaluated.",1
"The increasing importance of resource-efficient pro- duction entails that manufacturing companies have to create a more dynamic production environment, with flexible manufac- turing machines and processes. To fully utilize this potential of dynamic manufacturing through automatic production planning, formal skill descriptions of the machines are essential. How- ever, generating those skill descriptions in a manual fashion is labor-intensive and requires extensive domain-knowledge. In this contribution to the field of machine learning, we present a method to automatically generate training models from the manual, and discuss how these models can be used to train an automated system on a variety of available domains .",0
"Task and motion planning problems in robotics typically combine symbolic planning over discrete task variables with motion optimization over continuous state and action vari- ables, resulting in trajectories that satisfy the logical constraints imposed on the task variables. Symbolic planning can scale exponentially with the number of task variables, so recent works such as PDDLStream [1] have focused on optimistic planning with an incrementally growing set of objects and facts until a feasible trajectory is found. However, this set is exhaustively and uniformly expanded in a breadth-first manner, regardless of the geometric structure of the problem at hand, which makes long-horizon reasoning with large numbers of objects prohibitively time-consuming. To address this issue, we propose a geometrically informed symbolic planner that expands the set of objects and facts in a best-first manner, prioritized by a Graph Neural Network based score that is learned from prior search computations. We evaluate our approach on a diverse set of problems and demonstrate an improved ability to plan in large or difficult scenarios. We also apply our algorithm on a 7DOF robotic arm in several block-stacking manipulation tasks.",1
"Task and motion planning problems in robotics typically combine symbolic planning over discrete task variables with motion optimization over continuous state and action vari- ables, resulting in trajectories that satisfy the logical constraints imposed on the task variables. Symbolic planning can scale exponentially with the number of task variables, so recent works such as PDDLStream [1] have focused on optimistic planning with an incrementally growing set of objects and facts until a feasible trajectory is found. However, this set is exhaustively and uniformly expanded in a breadth-first manner, regardless of the geometric structure of the problem at hand, which makes long-horizon reasoning with large numbers of objects prohibitively time-consuming. To address this issue, we propose a geometrically informed symbolic planner that expands the set of objects and facts in a best-first manner, prioritized by a Graph Neural Network based score that is learned from prior search computations. We evaluate our approach on several tasks, including object recognition and movement detection, as well as on other non-objective tasks that focus on movement detection. We also apply our algorithm on a 7DOF robotic arm in several block-stacking manipulation tasks.",0
"We introduce a voting model with multi-agent ranked delegations. This model generalises liquid democracy in two aspects: first, an agent’s delega- tion can use the votes of multiple other agents to determine their own—for instance, an agent’s vote may correspond to the majority outcome of the votes of a trusted group of agents; second, agents can submit a ranking over multiple delegations, so that a backup delegation can be used when their preferred delegations are involved in cycles. The main focus of this paper is the study of unravelling procedures that transform the delegation ballots received from the agents into a profile of direct votes, from which a winning alternative can then be determined by using a standard voting rule. We pro- pose and study six such unravelling procedures, two based on optimisation and four using a greedy approach. We study both algorithmic and axiomatic properties, as well as related computational complexity problems of our un- ravelling procedures for different restrictions on the types of ballots that the agents can submit.",1
"We introduce a voting model with multi-agent ranked delegations. This model generalises liquid democracy in two aspects: first, an agent’s delega- tion can use the votes of multiple other agents to determine their own—for instance, an agent’s vote may correspond to the majority outcome of the votes of a trusted group of agents; second, agents can submit a ranking over multiple delegations, so that a backup delegation can be used when their preferred delegations are involved in cycles. The main focus of this paper is the study of unravelling procedures that transform the delegation ballots received from the agents into a profile of direct votes, from which a winning alternative can then be determined by using a standard voting rule. We pro- pose three approaches, with the majority objective being that all the voting procedures are sufficient to ensure the best possible performance of the extracted voting set. We study both algorithmic and axiomatic properties, as well as related computational complexity problems of our un- ravelling procedures for different restrictions on the types of ballots that the agents can submit.",0
"Our brain consists of biological neurons encoding information through accurate spike timing, yet both the architecture and learning rules of our brain remain largely unknown. Comparing to the recent development of backpropagation-based (BP-based) methods that are able to train spiking neural networks (SNNs) with high accuracy, biologically plausible methods are still in their infancy. In this work, we wish to answer the question of whether it is possible to attain compara- ble accuracy of SNNs trained by BP-based rules with bio-plausible mechanisms. We propose a new bio-plausible learning framework, consisting of two compo- nents: a new architecture, and its supporting learning rules. With two types of cells and four types of synaptic connections, the proposed local microcircuit ar- chitecture can compute and propagate error signals through local feedback con- nections and support training of multi-layers SNNs with a globally defined spik- ing error function. Under our microcircuit architecture, we employ the Spike- Timing-Dependent-Plasticity (STDP) rule operating in local compartments to up- date synaptic weights and achieve supervised learning in a biologically plausi- ble manner. Finally, We interpret the proposed framework from an optimization point of view and show the equivalence between it and the BP-based rules un- der a special circumstance. Our experiments show that the proposed framework demonstrates learning accuracy comparable to BP-based rules and may provide new insights on how learning is orchestrated in biological systems.",1
"Our brain consists of biological neurons encoding information through accurate spike timing, yet both the architecture and learning rules of our brain remain largely unknown. Comparing to the recent development of backpropagation-based (BP-based) methods that are able to train spiking neural networks (SNNs) with high accuracy, biologically plausible methods are still in their infancy. In this work, we wish to answer the question of whether it is possible to attain compara- ble accuracy of SNNs trained by BP-based rules with bio-plausible mechanisms. We propose a novel technique to extract information from SNNs  by introducing a new layer of pre-trained acoustic models for detecting and inferring natural language errors. With two types of cells and four types of synaptic connections, the proposed local microcircuit ar- chitecture can compute and propagate error signals through local feedback con- nections and support training of multi-layers SNNs with a globally defined spik- ing error function. Under our microcircuit architecture, we employ the Spike- Timing-Dependent-Plasticity (STDP) rule operating in local compartments to up- date synaptic weights and achieve supervised learning in a biologically plausi- ble manner. Finally, We interpret the proposed framework from an optimization point of view and show the equivalence between it and the BP-based rules un- der a special circumstance. Our experiments show that the proposed framework demonstrates learning accuracy comparable to BP-based rules and may provide new insights on how learning is orchestrated in biological systems.",0
"In recent years there has been a resurgence of interest in our community in the shape analysis of 3D objects represented by surface meshes, their voxelized interiors, or surface point clouds. In part, this interest has been stimulated by the increased availability of RGBD cameras, and by applications of computer vision to autonomous driving, medical imaging, and robotics. In these settings, spectral coordinates have shown promise for shape representation due to their ability to incorporate both local and global shape properties in a manner that is qualitatively invariant to isometric transformations. Yet, surprisingly, such coordinates have thus far typically considered only local surface positional or derivative information. In the present article, we propose to equip spectral coordinates with medial (object width) information, so as to enrich them. The key idea is to couple surface points that share a medial ball, via the weights of the adjacency matrix. We develop a spectral feature using this idea, and the algorithms to compute it. The incorporation of object width and medial coupling has direct benefits, as illustrated by our experiments on object classification, object part segmentation, and surface point correspondence.",1
"In recent years there has been a resurgence of interest in our community in the shape analysis of 3D objects represented by surface meshes, their voxelized interiors, or surface point clouds. In part, this interest has been stimulated by the increased availability of RGBD cameras, and by applications of computer vision to autonomous driving, medical imaging, and robotics. In these settings, spectral coordinates have shown promise for shape representation due to their ability to incorporate both local and global shape properties in a manner that is qualitatively invariant to isometric transformations. Yet, surprisingly, such coordinates have thus far typically considered only local surface positional or derivative information. In the present article, we propose to develop an augmented-system for modeling the surface of 3D object models with the help of the spectral component of the vector space. The key idea is to couple surface points that share a medial ball, via the weights of the adjacency matrix. We develop a spectral feature using this idea, and the algorithms to compute it. The incorporation of object width and medial coupling has direct benefits, as illustrated by our experiments on object classification, object part segmentation, and surface point correspondence.",0
"Evacuation shelters, which are urgently required during natural disasters, are designed to minimize the burden of evacuation on human survivors. However, the larger the scale of the disaster, the more costly it becomes to operate shelters. When the number of evacuees decreases, the operation costs can be reduced by moving the remaining evacuees to other shelters and closing shelters as quickly as possible. On the other hand, relocation between shelters imposes a huge emotional burden on evacuees. In this study, we formulate the “Evacuation Shelter Scheduling Problem,” which allocates evacuees to shelters in such a way to minimize the movement costs of the evacuees and the operation costs of the shelters. Since it is difficult to solve this quadratic programming problem directly, we show its transformation into a 0-1 integer programming problem. In addition, such a formulation struggles to calculate the burden of relocating them from historical data because no payments are actually made. To solve this issue, we propose a method that estimates movement costs based on the numbers of evacuees and shelters during an actual disaster. Simulation experiments with records from the Kobe earthquake (Great Hanshin-Awaji Earthquake) showed that our proposed method reduced operation costs by 33.7 million dollars: 32%.",1
"Evacuation shelters, which are urgently required during natural disasters, are designed to minimize the burden of evacuation on human survivors. However, the larger the scale of the disaster, the more costly it becomes to operate shelters. When the number of evacuees decreases, the operation costs can be reduced by moving the remaining evacuees to other shelters and closing shelters as quickly as possible. On the other hand, relocation between shelters imposes a huge emotional burden on evacuees. In this study, we formulate the “Evacuation Shelter Scheduling Problem,” which allocates evacuees to shelters in such a way to minimize the movement costs of the evacuees and the operation costs of the shelters. Since it is difficult to solve this quadratic programming problem directly, we show its transformation into a 0-1 integer programming problem. In addition, such a formulation struggles to calculate the burden of relocating them from historical data because no payments are actually made. To solve this issue, we propose a “Simulated Evaluation Project”, which is modeled on a parallel data set.  Simulation experiments with records from the Kobe earthquake (Great Hanshin-Awaji Earthquake) showed that our proposed method reduced operation costs by 33.7 million dollars: 32%.",0
"Inconsistency in prediction problems occurs when instances that relate in a certain way on condition attributes, do not follow the same relation on the decision attribute. For example, in ordinal classification with monotonicity constraints, it occurs when an instance dominating another instance on con- dition attributes has been assigned to a worse decision class. It typically appears as a result of perturbation in data caused by incomplete knowledge (missing attributes) or by random effects that occur during data generation (instability in the assessment of decision attribute values). Inconsistencies with respect to a crisp preorder relation (expressing either dominance or in- discernibility between instances) can be handled using symbolic approaches like rough set theory and by using statistical/machine learning approaches that involve optimization methods. Fuzzy rough sets can also be seen as a symbolic approach to inconsistency handling with respect to a fuzzy relation. In this article, we introduce a new machine learning method for inconsistency handling with respect to a fuzzy preorder relation. The novel approach is motivated by the existing machine learning approach used for crisp relations. We provide statistical foundations for it and develop optimization procedures that can be used to eliminate inconsistencies. The article also proves impor- tant properties and contains didactic examples of those procedures.",1
"Inconsistency in prediction problems occurs when instances that relate in a certain way on condition attributes, do not follow the same relation on the decision attribute. For example, in ordinal classification with monotonicity constraints, it occurs when an instance dominating another instance on con- dition attributes has been assigned to a worse decision class. It typically appears as a result of perturbation in data caused by incomplete knowledge (missing attributes) or by random effects that occur during data generation (instability in the assessment of decision attribute values). Inconsistencies with respect to a crisp preorder relation (expressing either dominance or in- discernibility between instances) can be handled using symbolic approaches like rough set theory and by using statistical/machine learning approaches that involve optimization methods. Fuzzy rough sets can also be seen as a symbolic approach to inconsistency handling with respect to a fuzzy relation. In this article, we propose a new approach that introduces a soft dependency in a context-dependent fashion , while still preserving the traditional approach of dependency parsing in a formal sense.  The novel approach is motivated by the existing machine learning approach used for crisp relations. We provide statistical foundations for it and develop optimization procedures that can be used to eliminate inconsistencies. The article also proves impor- tant properties and contains didactic examples of those procedures.",0
"A key distinguishing feature of conversational recommender sys- tems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predomi- nant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main con- tributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that our approach is effective in selecting review sentences and transforming them to elicitation questions, even with limited training data. Addition- ally, we provide an analysis of patterns where the model does not perform optimally.",1
"A key distinguishing feature of conversational recommender sys- tems over traditional recommender systems is their ability to elicit user preferences using natural language. Currently, the predomi- nant approach to preference elicitation is to ask questions directly about items or item attributes. These strategies do not perform well in cases where the user does not have sufficient knowledge of the target domain to answer such questions. Conversely, in a shopping setting, talking about the planned use of items does not present any difficulties, even for those that are new to a domain. In this paper, we propose a novel approach to preference elicitation by asking implicit questions based on item usage. Our approach consists of two main steps. First, we identify the sentences from a large review corpus that contain information about item usage. Then, we generate implicit preference elicitation questions from those sentences using a neural text-to-text model. The main con- tributions of this work also include a multi-stage data annotation protocol using crowdsourcing for collecting high-quality labeled training data for the neural model. We show that our approach is effective at generating responses from a large corpus of data and is relatively effective at generating explicit and ambiguous responses from such data. Addition- ally, we provide an analysis of patterns where the model does not perform optimally.",0
"Focusing on discriminative zero-shot learning, in this work we introduce a novel mechanism that dynamically augments during training the set of seen classes to produce additional fictitious classes. These fictitious classes diminish the model’s tendency to fixate during training on attribute corre- lations that appear in the training set but will not appear in newly exposed classes. The proposed model is tested within the two formulations of the zero-shot learning framework; namely, gener- alized zero-shot learning (GZSL) and classical zero-shot learning (CZSL). Our model improves the state-of-the-art performance on the CUB dataset and reaches comparable results on the other common datasets, AWA2 and SUN. We investigate the strengths and weaknesses of our method, including the effects of catastrophic forgetting when training an end-to-end zero-shot model.",1
"Focusing on discriminative zero-shot learning, in this work we introduce a novel mechanism that dynamically augments during training the set of seen classes to produce additional fictitious classes. These fictitious classes diminish the model’s tendency to fixate during training on attribute corre- lations that appear in the training set but will not appear in newly exposed classes. The proposed model is tested within the two formulations of the zero-shot learning framework; namely, gener- alized zero-shot learning (GZSL) and classical zero-shot learning (CZSL). Our model improves the state-of-the-art performance on the CUB dataset and reaches comparable results on the other common datasets, AWA2 and SUN. We investigate the effect of using a discriminative method for training model classes and show that it outperforms CZSL.",0
"How to evaluate the importance of nodes is essential in research of complex network. There are many methods proposed for solving this problem, but they still have room to be improved. In this paper, a new approach called local volume information dimension is proposed. In this method, the sum of degree of nodes within different distances of central node is calculated. The information within the certain distance is described by the information entropy. Compared to other methods, the proposed method considers the information of the nodes from different distances more comprehensively. For the purpose of showing the effectiveness of the proposed method, experiments on real-world networks are implemented. Promising results indicate the effectiveness of the proposed method.",1
"How to evaluate the importance of nodes is essential in research of complex network. There are many methods proposed for solving this problem, but they still have room to be improved. In this paper, a new approach called local volume information dimension is proposed. In this method, the node-level information dimension is used to define the attention-response relationship between nodes in a graph. The information within the certain distance is described by the information entropy. Compared to other methods, the proposed method considers the information of the nodes from different distances more comprehensively. For the purpose of showing the effectiveness of the proposed method, experiments on real-world networks are implemented. Promising results indicate the effectiveness of the proposed method.",0
"Do language models have beliefs about the world? Dennett (1995) famously argues that even thermostats have beliefs, on the view that a belief is simply an informational state decou- pled from any motivational state. In this paper, we discuss approaches to detecting when mod- els have beliefs about the world, and we im- prove on methods for updating model beliefs to be more truthful, with a focus on methods based on learned optimizers or hypernetworks. Our main contributions include: (1) new met- rics for evaluating belief-updating methods that focus on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing model updates (SLAG) that improves the performance of learned optimiz- ers, and (3) the introduction of the belief graph, which is a new form of interface with language models that shows the interdependencies be- tween model beliefs. Our experiments sug- gest that models possess belief-like qualities to only a limited extent, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the- shelf optimizers are surprisingly strong belief- updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",1
"Do language models have beliefs about the world? Dennett (1995) famously argues that even thermostats have beliefs, on the view that a belief is simply an informational state decou- pled from any motivational state. In this paper, we discuss approaches to detecting when mod- els have beliefs about the world, and we im- prove on methods for updating model beliefs to be more truthful, with a focus on methods based on learned optimizers or hypernetworks. Our main contributions include: (1) new met- rics for evaluating belief-updating methods that focus on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing model updates (SLAG) that improves the performance of learned optimiz- ers, and (3) the introduction of the belief graph, which is a new form of interface with language models that shows the interdependencies be- tween model beliefs. Our experiments sug- gest the importance of model beliefs in  learning models, and we show that the approach outperforms  automatic model updating systems using word representations. Although off-the- shelf optimizers are surprisingly strong belief- updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.",0